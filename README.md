ğŸ§  Lab Assignment Submission

This repository contains solutions for the given take-home lab assignment.

âš™ï¸ Q1: Vision Transformer on CIFAR-10
ğŸ”¹ How to Run

Open q1.ipynb in Google Colab with a GPU runtime enabled.

Connect to Google Drive when prompted by the first cell.

Run all cells sequentially from top to bottom.

The notebook will:

Train the model

Save the best-performing version to Google Drive

Display the final accuracy

ğŸ“Š Best Model Configuration
Parameter	Value
Epochs Trained	15
Patch Size	4Ã—4
Model Depth	7
Embedding Dimension	384
Optimizer	AdamW with CosineAnnealingLR
ğŸ§ª Results
Model	Test Accuracy
ViT (15 Epochs)	70.68%
ğŸ–¼ï¸ Q2: Text-Driven Image Segmentation with SAM
ğŸ”¹ Pipeline Description

The notebook q2.ipynb demonstrates text-prompted image segmentation using pre-trained models.

Workflow Overview

Text-to-Box:
Uses GroundingDINO to take a text prompt (e.g., â€œa dogâ€) and an image, generating bounding boxes for the described object.

Box-to-Mask:
The bounding boxes are passed as prompts to the Segment Anything Model (SAM).

Segmentation:
SAM produces a precise segmentation mask for the detected object.

Visualization:
The final mask is overlaid on the original image using the Supervision library.

âš ï¸ Limitations

The mask quality depends heavily on the bounding boxes generated by GroundingDINO â€” vague prompts may yield inaccurate results.

The current implementation supports only one object prompt per image.

ğŸ§© Note on SAM 2

Although the assignment mentioned SAM 2, its limited public availability led to the use of the original and widely adopted Segment Anything Model (SAM) by Meta AI for this implementation.

ğŸ“‚ Repository Structure
Lab-Assignment/
â”œâ”€â”€ q1.ipynb   # Vision Transformer on CIFAR-10
â”œâ”€â”€ q2.ipynb   # Text-Driven Image Segmentation using SAM
â””â”€â”€ README.md  # Project Documentation

ğŸ™Œ Acknowledgements

Vision Transformer (ViT) â€” Google Research

GroundingDINO â€” IDEA Research

Segment Anything Model (SAM) â€” Meta AI

Supervision Library â€” Roboflow
